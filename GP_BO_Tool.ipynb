{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristopherLuey/Northwestern-ME-441-Gaussian-Process-Bayesian-Optimization-Tool/blob/main/GP_BO_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Process Baeysian Optimization Tool\n",
        "\n",
        "**First, upload a CSV file with experimental data**\n",
        "\n",
        "Data should be in the following format:\n",
        "\n",
        "```\n",
        "Column 1 | Column 2 | ... | Column n\n",
        "x1       | x2       | ... | y\n",
        "```\n",
        "Columns represent design variables, rows represent different sample points. There should be no headers, just data.\n",
        "\n",
        "\n",
        "Example for 1D case:\n",
        "\n",
        "```\n",
        "0.529\t0.991\n",
        "1.899\t0\n",
        "7\t    -4.959\n",
        "3.7\t  -2.495\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# Follow these steps to use this code:\n",
        "```\n",
        "1. Run this to start\n",
        "2. Set file_name to the path of the CSV file and run\n",
        "3. Run this to indicate the inclusive limits of the design space\n",
        "4. Run this to determine the point of greatest acquisition\n",
        "5. Run this to graph the result for 1D or 2D cases\n",
        "6. Run this to determine the mean and covariance at a specific point\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ViHDb0XAbYI7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuE8gwWCYnBE"
      },
      "outputs": [],
      "source": [
        "# @title 1. GP BO Tool IDEAL Lab { form-width: \"100%\", display-mode: \"form\" }\n",
        "# Run\n",
        "!pip install gpytorch -q\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gpytorch\n",
        "import math\n",
        "import torch\n",
        "import pandas as pd\n",
        "from scipy.stats import differential_entropy, norm\n",
        "from itertools import product\n",
        "import os\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.CRITICAL)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# @title Runtime > Run All\n",
        "class GPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood):\n",
        "        super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n",
        "# Expected improvement, minimize y\n",
        "def calculate_acf(pred_mean, pred_std, y_max):\n",
        "    improve = y_max - pred_mean\n",
        "    z_score = np.divide(improve, pred_std + 1e-9)\n",
        "    acf = np.multiply(improve, norm.cdf(z_score)) + np.multiply(pred_std, norm.pdf(z_score))\n",
        "    return max(acf,0)\n",
        "\n",
        "def train_GP(train_x, train_y, train_iter):\n",
        "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\n",
        "    likelihood.noise = 10 ** -8\n",
        "    model = GPModel(train_x, train_y, likelihood)\n",
        "    model.train()\n",
        "    likelihood.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "    for i in range(train_iter):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(train_x)\n",
        "        loss = -mll(output, train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model, likelihood\n",
        "\n",
        "def predict_GP(GP_model, x):\n",
        "  GP_model.eval()\n",
        "  with torch.no_grad():\n",
        "    f_preds = GP_model(x)\n",
        "  return f_preds\n",
        "\n",
        "def get_indices(index, dimensions):\n",
        "    indices = []\n",
        "    for dim_size in reversed(dimensions):\n",
        "        index, remainder = divmod(index, dim_size)\n",
        "        indices.insert(0, remainder)\n",
        "    return tuple(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNzFo54nwOHX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 2. Add the path to the csv file\n",
        "\n",
        "# Indicate the search space\n",
        "sample_size = 100\n",
        "\n",
        "# Indicate the file path\n",
        "# To get the file path: right click on the file and click copy path\n",
        "file_name = \"PathToFile.csv\"\n",
        "\n",
        "assert os.path.exists(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Indicate the size of the design space limits\n",
        "\n",
        "x = pd.read_csv(file_name, dtype=np.float64, header=None).to_numpy()\n",
        "\n",
        "n = x.shape[1]-1\n",
        "print(\"Detected {} dimesional space\".format(n))\n",
        "limits = []\n",
        "\n",
        "for i in range(n):\n",
        "  l = float(input(\"Enter the lower limit for x{}: \".format(i+1)))\n",
        "  u = float(input(\"Enter the upper limit for x{}: \".format(i+1)))\n",
        "  limits.append([l, u])\n",
        "  print()\n",
        "\n",
        "space_size = tuple([sample_size] * n)\n",
        "x_sample_space = np.empty(sample_size).T\n",
        "for i in range(n):\n",
        "  _ = np.linspace(limits[i][0], limits[i][1],sample_size)\n",
        "  x_sample_space = np.vstack((x_sample_space, _))\n",
        "x_sample_space = x_sample_space[1:]\n",
        "dimensions = np.array([sample_size]*n)"
      ],
      "metadata": {
        "id": "1CC-o3TtY174",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_1Tm4Lzsv_-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 4. Run to perform GP BO\n",
        "iterations = 1\n",
        "for i in range(iterations):\n",
        "  inx = torch.from_numpy(x[:, :-1])\n",
        "  iny = torch.from_numpy(x[:, -1])\n",
        "  GP_model, GP_likelihood = train_GP(inx, iny, train_iter=1000)\n",
        "\n",
        "  acq_func = np.zeros(tuple([sample_size] * n))\n",
        "  mean = np.zeros(tuple([sample_size] * n))\n",
        "  variance = np.zeros(tuple([sample_size] * n))\n",
        "  lower_variance = np.zeros(tuple([sample_size] * n))\n",
        "  mesh = {}\n",
        "\n",
        "  GP_model.eval()\n",
        "  GP_likelihood.eval()\n",
        "\n",
        "  for index, point in enumerate(product(*x_sample_space)):\n",
        "      indices = get_indices(index, dimensions)\n",
        "      mesh[indices] = point\n",
        "      input_value = torch.from_numpy(np.asarray(point))[None,:]\n",
        "\n",
        "      model_preds = predict_GP(GP_model, input_value)\n",
        "\n",
        "      acq_func[indices] = calculate_acf(model_preds.mean.numpy(), torch.sqrt(model_preds.variance).numpy(), np.min(x[-1]))\n",
        "      mean[indices] = model_preds.mean.numpy()[0]\n",
        "      variance[indices] = 1.96 * np.sqrt(model_preds.variance.numpy())\n",
        "\n",
        "  location = np.unravel_index(acq_func.argmax(), acq_func.shape)\n",
        "  te = mesh[location]\n",
        "  print(\"Analyze points: {}\".format(te))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Helper Functions"
      ],
      "metadata": {
        "id": "Sh1gUAPrbqnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Plot 1D and 2D cases\n",
        "if len(mean.shape) == 2:\n",
        "    x, y = np.meshgrid(*x_sample_space)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.plot_surface(x, y, mean, facecolors=plt.cm.viridis(mean / np.max(mean)), alpha=0.5, linewidth=0)\n",
        "\n",
        "    # # Plot upper variance\n",
        "    # ax.plot_surface(x, y, mean + variance, facecolors=plt.cm.cividis(mean / np.max(mean)), alpha=0.5, linewidth=0)\n",
        "\n",
        "    # # Plot lower variance\n",
        "    # ax.plot_surface(x, y, mean - variance, facecolors=plt.cm.inferno(mean / np.max(mean)), alpha=0.5, linewidth=0)\n",
        "    ax.scatter(x[:,0], x[:, 1], x[:, 2], c=x[:,2], cmap='viridis')\n",
        "    ax.set_xlabel('X axis')\n",
        "    ax.set_ylabel('Y axis')\n",
        "    ax.set_zlabel('Z axis')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "if len(mean.shape) == 1:\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(x.T[0],x.T[1], label=\"3\")\n",
        "    ax.plot(x_sample_space.T, mean, label=\"4\")\n",
        "    ax.fill_between(x_sample_space[0].T, (mean-variance), (mean+variance),alpha=0.3)\n",
        "    plt.show()\n",
        "    plt.plot(x_sample_space[0].T, acq_func, label=\"2\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jTaqz18obIz3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Query a specific point\n",
        "p = []\n",
        "for i in range(n):\n",
        "  p.append(float(input(\"Query for x{}: \".format(i))))\n",
        "\n",
        "p = np.array(p)\n",
        "input_value = torch.from_numpy(np.asarray(p))[None,:]\n",
        "\n",
        "model_preds = predict_GP(GP_model, input_value)\n",
        "print(\"The mean is {} and the variance is {} at the point {}\".format(model_preds.mean.numpy(), 1.96 * np.sqrt(model_preds.variance.numpy()), p))"
      ],
      "metadata": {
        "id": "GL6pkUJ-uQTL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}